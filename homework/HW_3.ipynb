{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS211: Data Privacy\n",
    "## Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from unittest.mock import patch\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "adult = pd.read_csv('https://github.com/jnear/cs211-data-privacy/raw/master/homework/adult_with_pii.csv')\n",
    "adult = adult.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (10 points)\n",
    "\n",
    "Write code to answer the query: \"how many participants have never been married?\"\n",
    "\n",
    "*Hint*: filter the `adult_data` dataframe to contain only participants who were never married, then return the  `len` of the filtered dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f1f7e0158a3e66d86f5d3d51a7ed30f",
     "grade": false,
     "grade_id": "cell-975eb03979d78eaf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def query1():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "query1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "674e4c2da585cbb9e92ee8a546628647",
     "grade": true,
     "grade_id": "cell-c5ba2c93a46e8c5e",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE for question 1\n",
    "assert query1() == 9726"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (5 points)\n",
    "\n",
    "In 2-5 sentences, answer the following:\n",
    "- What is the sensitivity of `query1`, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a49f719e7bbff7b4331d41682658d904",
     "grade": true,
     "grade_id": "cell-fb1c7b0533f933f7",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (10 points)\n",
    "\n",
    "Use the implementation of `laplace_mech` to produce a differentially private answer to `query1`, with `epsilon = 0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e27ddd40ababa8eee863cbbeb1961b2",
     "grade": false,
     "grade_id": "cell-80d3c108ba0f75d5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dp_query1(epsilon):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "dp_query1(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f93d4f28b6a3727ed76df8885baeb8a",
     "grade": true,
     "grade_id": "cell-93eab43d27806309",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE for question 3\n",
    "dp_results = [dp_query1(0.1) for _ in range(100)]\n",
    "spec = [np.random.laplace(loc=9726, scale=1/0.1) for _ in range(100)]\n",
    "assert stats.wasserstein_distance(dp_results, spec) < 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (10 points)\n",
    "\n",
    "The `pct_error` function, defined below, returns the percent relative error between an original query result and a differentially private result for the same query.\n",
    "\n",
    "Implement a function `graph_error1` that:\n",
    "\n",
    "- Calculates 1000 differentially private answers to `dp_query1`\n",
    "- Calculates the percent error for each one of these answers against the original (non-private) answer\n",
    "- Graphs the distribution of errors using a histogram\n",
    "\n",
    "*Hint*: use `plt.hist(..., bins=20)`.\n",
    "\n",
    "The given code will use your function to plot errors for `epsilon=0.1` and `epsilon=1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0629316da63126e9cb985ce2dd54c40",
     "grade": false,
     "grade_id": "cell-da0c198a1cf9a866",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def graph_error1(epsilon):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "graph_error1(0.1)\n",
    "graph_error1(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3361b8760594145c039d41479c981de4",
     "grade": true,
     "grade_id": "cell-eda6bc27840a9067",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "error_spec = 100.0 * np.abs(np.random.laplace(loc=0, scale=1, size=1000)) / query1()\n",
    "\n",
    "with patch('matplotlib.pyplot.hist') as mock_hist:\n",
    "    graph_error1(1.0)\n",
    "    \n",
    "args, kwargs = mock_hist.call_args\n",
    "assert stats.wasserstein_distance(error_spec, args[0]) < 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (10 points)\n",
    "\n",
    "In 2-5 sentences, answer the following:\n",
    "\n",
    "- How does the histogram of relative errors for $\\epsilon = 0.1$ differ from the one for $\\epsilon = 1.0$?\n",
    "- What do the two histograms tell you about the effect of $\\epsilon$ on relative error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce2bae13a992d9010fab785450105fd6",
     "grade": true,
     "grade_id": "cell-075013c43cc4cc1d",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (10 points)\n",
    "\n",
    "Consider `query2`, which asks how many people in the dataset are over the age of 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query2():\n",
    "    return len(adult[adult['Age'] > 60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement `dp_query2`, a differentially private version of `query2` (as in question 3), and `graph_error2`, which graphs relative error for `dp_query2` (as in question 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa2b1a0e097669458441b4208bdb099e",
     "grade": false,
     "grade_id": "cell-1c15ba7324d807a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dp_query2(epsilon):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def graph_error2(epsilon):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "graph_error2(1.0)\n",
    "graph_error1(1.0) # we plot both errors for query 1 and query 2 at the same epsilon, to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "015fdbec71d505db6698ac9ebb460e18",
     "grade": true,
     "grade_id": "cell-239ae948aa08f924",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "error_spec = 100.0 * np.abs(np.random.laplace(loc=0, scale=1, size=1000)) / query2()\n",
    "\n",
    "with patch('matplotlib.pyplot.hist') as mock_hist:\n",
    "    graph_error2(1.0)\n",
    "    \n",
    "args, kwargs = mock_hist.call_args\n",
    "assert stats.wasserstein_distance(error_spec, args[0]) < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 (10 points)\n",
    "\n",
    "In 2-5 sentences, answer the following:\n",
    "\n",
    "- Given the graph from question 6, how does relative error differ between `dp_query1` and `dp_query2` for the same value of $\\epsilon$?\n",
    "- What property of the query causes the difference in relative errors between `dp_query1` and `dp_query2`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36649d5ca3c4a6845f7caa5d7952d216",
     "grade": true,
     "grade_id": "cell-be5745d92a22154c",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
